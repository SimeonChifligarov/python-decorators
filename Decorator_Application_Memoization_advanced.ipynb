{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decorators Application — Memoization (Advanced Problems + Solutions)\n",
    "\n",
    "This notebook contains advanced memoization exercises (with solutions) using decorators.\n",
    "\n",
    "Topics:\n",
    "- Correct memoization keys for `args/kwargs`\n",
    "- Handling unhashable inputs via deep-freezing\n",
    "- Bounded caches (LRU)\n",
    "- TTL expiration\n",
    "- Exception caching policy\n",
    "- Async memoization with concurrency de-duplication\n",
    "- Per-instance method memoization without memory leaks (weakrefs)\n",
    "- Best-practice use of `functools.lru_cache`, `functools.cache`, and `cached_property`\n"
   ],
   "id": "f334e189d44edbdb"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "setup"
    ],
    "ExecuteTime": {
     "end_time": "2026-02-06T18:23:27.811123500Z",
     "start_time": "2026-02-06T18:23:27.789893300Z"
    }
   },
   "source": [
    "import asyncio\n",
    "import functools\n",
    "import inspect\n",
    "import threading\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Callable, Hashable\n",
    "from weakref import WeakKeyDictionary\n"
   ],
   "id": "e9a946bc5f284cfb",
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "## Exercise 1 — Memoization basics: prove the repeated-work problem\n",
    "\n",
    "Write a naive recursive Fibonacci implementation and show that it repeats work.\n",
    "\n",
    "Requirements:\n",
    "- Use 1-based indexing: F(1)=1, F(2)=1\n",
    "- Track how many times the function is called for `n=10`\n",
    "\n",
    "Then (in later exercises) you'll fix it with memoization.\n"
   ],
   "id": "dafda8a6d006b596"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "solution"
    ],
    "ExecuteTime": {
     "end_time": "2026-02-06T18:23:28.576481500Z",
     "start_time": "2026-02-06T18:23:28.515663700Z"
    }
   },
   "source": [
    "# --- Solution (Exercise 1) ---\n",
    "\n",
    "def count_calls(fn: Callable[..., Any]):\n",
    "    \"\"\"Simple call counter decorator used for measurement in this notebook.\"\"\"\n",
    "    count = 0\n",
    "\n",
    "    @functools.wraps(fn)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        nonlocal count\n",
    "        count += 1\n",
    "        wrapper.call_count = count  # type: ignore[attr-defined]\n",
    "        return fn(*args, **kwargs)\n",
    "\n",
    "    wrapper.call_count = 0  # type: ignore[attr-defined]\n",
    "    return wrapper\n",
    "\n",
    "@count_calls\n",
    "def fib_naive_counted(n: int) -> int:\n",
    "    \"\"\"Naive recursive Fibonacci (1-based), with correct recursive call counting.\"\"\"\n",
    "    if n <= 0:\n",
    "        raise ValueError('n must be >= 1')\n",
    "    return 1 if n <= 2 else fib_naive_counted(n - 1) + fib_naive_counted(n - 2)\n"
   ],
   "id": "27886f454575ca1c",
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo (Exercise 1)\n",
    "Naive recursion does a lot of repeated work; call counts grow quickly.\n"
   ],
   "id": "44994c8e2a4ff0bc"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "demo"
    ],
    "ExecuteTime": {
     "end_time": "2026-02-06T18:23:29.478397Z",
     "start_time": "2026-02-06T18:23:29.350368500Z"
    }
   },
   "source": [
    "fib_naive_counted.call_count = 0  # type: ignore[attr-defined]\n",
    "val = fib_naive_counted(10)\n",
    "val, fib_naive_counted.call_count  # type: ignore[attr-defined]\n"
   ],
   "id": "3fcc24f78d72a43",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 109)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "## Exercise 2 — A correct memoize decorator for args + kwargs\n",
    "\n",
    "Implement `memoize`:\n",
    "\n",
    "Requirements:\n",
    "- Works for arbitrary `*args` and `**kwargs`\n",
    "- Cache key must be stable regardless of kwargs order\n",
    "- Preserves metadata using `functools.wraps`\n",
    "- Exposes:\n",
    "  - `wrapper.cache_clear()`\n",
    "  - `wrapper.cache_info()` returning `{hits, misses, size}`\n",
    "\n",
    "Best practice: fail loudly on unhashable inputs (handled in Exercise 3).\n"
   ],
   "id": "70ec3337a22df810"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "solution"
    ],
    "ExecuteTime": {
     "end_time": "2026-02-06T18:23:29.994326500Z",
     "start_time": "2026-02-06T18:23:29.957833700Z"
    }
   },
   "source": [
    "# --- Solution (Exercise 2) ---\n",
    "\n",
    "def _default_key(args: tuple[Any, ...], kwargs: dict[str, Any]) -> Hashable:\n",
    "    # Raises TypeError if any element is unhashable.\n",
    "    return (args, tuple(sorted(kwargs.items())))\n",
    "\n",
    "def memoize(\n",
    "    fn: Callable[..., Any] | None = None,\n",
    "    *,\n",
    "    key: Callable[[tuple[Any, ...], dict[str, Any]], Hashable] | None = None,\n",
    "):\n",
    "    \"\"\"Memoize a function by caching results based on args/kwargs.\n",
    "\n",
    "    Usage:\n",
    "        @memoize\n",
    "        def f(...): ...\n",
    "\n",
    "        @memoize(key=custom_key)\n",
    "        def g(...): ...\n",
    "    \"\"\"\n",
    "\n",
    "    def decorate(target: Callable[..., Any]):\n",
    "        cache: dict[Hashable, Any] = {}\n",
    "        hits = 0\n",
    "        misses = 0\n",
    "        make_key = key if key is not None else _default_key\n",
    "\n",
    "        @functools.wraps(target)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            nonlocal hits, misses\n",
    "            k = make_key(args, kwargs)\n",
    "            if k in cache:\n",
    "                hits += 1\n",
    "                return cache[k]\n",
    "            misses += 1\n",
    "            val = target(*args, **kwargs)\n",
    "            cache[k] = val\n",
    "            return val\n",
    "\n",
    "        def cache_clear():\n",
    "            nonlocal hits, misses\n",
    "            cache.clear()\n",
    "            hits = 0\n",
    "            misses = 0\n",
    "\n",
    "        def cache_info():\n",
    "            return {'hits': hits, 'misses': misses, 'size': len(cache)}\n",
    "\n",
    "        wrapper.cache_clear = cache_clear  # type: ignore[attr-defined]\n",
    "        wrapper.cache_info = cache_info    # type: ignore[attr-defined]\n",
    "        return wrapper\n",
    "\n",
    "    if callable(fn):\n",
    "        return decorate(fn)\n",
    "    return decorate\n"
   ],
   "id": "a65b0d300f6805b5",
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "## Exercise 3 — Handle unhashable inputs via deep-freezing (advanced)\n",
    "\n",
    "Memoization keys must be hashable. Implement `deep_freeze(obj)` that converts:\n",
    "- `list` -> `tuple` (recursively)\n",
    "- `dict` -> sorted tuple of key/value pairs (recursively)\n",
    "- `set` -> `frozenset` (recursively)\n",
    "\n",
    "Then implement `memoize_frozen` that uses deep-freezing in its key builder.\n",
    "\n",
    "Best practices:\n",
    "- Only freeze known container types.\n",
    "- Do not attempt to freeze arbitrary custom objects (treat as-is).\n",
    "- Be explicit about limitations.\n"
   ],
   "id": "adc10bd6a0480838"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "solution"
    ],
    "ExecuteTime": {
     "end_time": "2026-02-06T18:23:30.653464800Z",
     "start_time": "2026-02-06T18:23:30.625504400Z"
    }
   },
   "source": [
    "# --- Solution (Exercise 3) ---\n",
    "\n",
    "def deep_freeze(obj: Any) -> Any:\n",
    "    \"\"\"Convert common mutable containers into immutable equivalents recursively.\n",
    "\n",
    "    Supported:\n",
    "      - list -> tuple\n",
    "      - dict -> tuple(sorted((k, v), ...))\n",
    "      - set -> frozenset\n",
    "      - tuple -> tuple (elements frozen)\n",
    "\n",
    "    Other objects are returned as-is.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, list):\n",
    "        return tuple(deep_freeze(x) for x in obj)\n",
    "    if isinstance(obj, dict):\n",
    "        return tuple(sorted((deep_freeze(k), deep_freeze(v)) for k, v in obj.items()))\n",
    "    if isinstance(obj, set):\n",
    "        return frozenset(deep_freeze(x) for x in obj)\n",
    "    if isinstance(obj, tuple):\n",
    "        return tuple(deep_freeze(x) for x in obj)\n",
    "    return obj\n",
    "\n",
    "def _frozen_key(args: tuple[Any, ...], kwargs: dict[str, Any]) -> Hashable:\n",
    "    frozen_args = deep_freeze(args)\n",
    "    frozen_kwargs = deep_freeze(kwargs)\n",
    "    return (frozen_args, frozen_kwargs)\n",
    "\n",
    "def memoize_frozen(fn: Callable[..., Any] | None = None):\n",
    "    return memoize(fn, key=_frozen_key)  # type: ignore[arg-type]\n"
   ],
   "id": "50a9941ca0a8606b",
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "## Exercise 4 — Bounded memoization: LRU cache decorator\n",
    "\n",
    "Implement `lru_memoize(maxsize=128, thread_safe=True)`:\n",
    "\n",
    "Requirements:\n",
    "- Keeps at most `maxsize` items; evict **least-recently-used**\n",
    "- Accepts args/kwargs keys (use `_default_key` from Exercise 2)\n",
    "- Thread-safe when `thread_safe=True`\n",
    "- Exposes:\n",
    "  - `cache_clear()`, `cache_info()` -> `{hits, misses, size, maxsize}`\n",
    "\n",
    "Best practice:\n",
    "- Compute the function result outside the lock to avoid blocking.\n",
    "- Only keep lock around cache mutation.\n"
   ],
   "id": "2d7775b8bb322878"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "solution"
    ],
    "ExecuteTime": {
     "end_time": "2026-02-06T18:23:31.191436800Z",
     "start_time": "2026-02-06T18:23:31.163272700Z"
    }
   },
   "source": [
    "# --- Solution (Exercise 4) ---\n",
    "\n",
    "def lru_memoize(\n",
    "    *,\n",
    "    maxsize: int = 128,\n",
    "    thread_safe: bool = True,\n",
    "    key: Callable[[tuple[Any, ...], dict[str, Any]], Hashable] | None = None,\n",
    "):\n",
    "    if maxsize < 1:\n",
    "        raise ValueError('maxsize must be >= 1')\n",
    "    make_key = key if key is not None else _default_key\n",
    "\n",
    "    def decorate(fn: Callable[..., Any]):\n",
    "        cache: OrderedDict[Hashable, Any] = OrderedDict()\n",
    "        hits = 0\n",
    "        misses = 0\n",
    "        lock = threading.Lock() if thread_safe else None\n",
    "\n",
    "        def _get(k: Hashable):\n",
    "            nonlocal hits\n",
    "            if k in cache:\n",
    "                hits += 1\n",
    "                cache.move_to_end(k, last=True)\n",
    "                return True, cache[k]\n",
    "            return False, None\n",
    "\n",
    "        def _put(k: Hashable, v: Any):\n",
    "            cache[k] = v\n",
    "            cache.move_to_end(k, last=True)\n",
    "            while len(cache) > maxsize:\n",
    "                cache.popitem(last=False)\n",
    "\n",
    "        @functools.wraps(fn)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            nonlocal misses\n",
    "            k = make_key(args, kwargs)\n",
    "\n",
    "            if lock is None:\n",
    "                ok, val = _get(k)\n",
    "                if ok:\n",
    "                    return val\n",
    "                misses += 1\n",
    "                val = fn(*args, **kwargs)\n",
    "                _put(k, val)\n",
    "                return val\n",
    "\n",
    "            # Locking path\n",
    "            with lock:\n",
    "                ok, val = _get(k)\n",
    "                if ok:\n",
    "                    return val\n",
    "                misses += 1\n",
    "\n",
    "            # Compute outside lock\n",
    "            val = fn(*args, **kwargs)\n",
    "\n",
    "            with lock:\n",
    "                _put(k, val)\n",
    "            return val\n",
    "\n",
    "        def cache_clear():\n",
    "            nonlocal hits, misses\n",
    "            if lock is None:\n",
    "                cache.clear()\n",
    "                hits = 0\n",
    "                misses = 0\n",
    "                return\n",
    "            with lock:\n",
    "                cache.clear()\n",
    "                hits = 0\n",
    "                misses = 0\n",
    "\n",
    "        def cache_info():\n",
    "            if lock is None:\n",
    "                return {'hits': hits, 'misses': misses, 'size': len(cache), 'maxsize': maxsize}\n",
    "            with lock:\n",
    "                return {'hits': hits, 'misses': misses, 'size': len(cache), 'maxsize': maxsize}\n",
    "\n",
    "        wrapper.cache_clear = cache_clear  # type: ignore[attr-defined]\n",
    "        wrapper.cache_info = cache_info    # type: ignore[attr-defined]\n",
    "        return wrapper\n",
    "\n",
    "    return decorate\n"
   ],
   "id": "5bdb4297cad6a4ce",
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "## Exercise 5 — TTL memoization (time-based expiration)\n",
    "\n",
    "Implement `ttl_memoize(ttl_seconds, maxsize=128, time_func=time.monotonic)`:\n",
    "\n",
    "Requirements:\n",
    "- Cache entries expire after `ttl_seconds`\n",
    "- Use LRU eviction when exceeding `maxsize`\n",
    "- Provide `cache_clear()` and `cache_info()` -> `{hits, misses, size, maxsize, ttl_seconds}`\n",
    "\n",
    "Best practice:\n",
    "- Accept an injectable `time_func` so tests don't need real sleeping.\n",
    "- Purge expired entries opportunistically on access.\n"
   ],
   "id": "7c89208c03b3e89a"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "solution"
    ],
    "ExecuteTime": {
     "end_time": "2026-02-06T18:23:31.842510100Z",
     "start_time": "2026-02-06T18:23:31.809050700Z"
    }
   },
   "source": [
    "# --- Solution (Exercise 5) ---\n",
    "\n",
    "def ttl_memoize(\n",
    "    *,\n",
    "    ttl_seconds: float,\n",
    "    maxsize: int = 128,\n",
    "    time_func: Callable[[], float] = time.monotonic,\n",
    "    key: Callable[[tuple[Any, ...], dict[str, Any]], Hashable] | None = None,\n",
    "):\n",
    "    if ttl_seconds <= 0:\n",
    "        raise ValueError('ttl_seconds must be > 0')\n",
    "    if maxsize < 1:\n",
    "        raise ValueError('maxsize must be >= 1')\n",
    "    make_key = key if key is not None else _default_key\n",
    "\n",
    "    def decorate(fn: Callable[..., Any]):\n",
    "        # OrderedDict: key -> (expires_at, value)\n",
    "        cache: OrderedDict[Hashable, tuple[float, Any]] = OrderedDict()\n",
    "        hits = 0\n",
    "        misses = 0\n",
    "\n",
    "        def _purge_expired(now: float):\n",
    "            # LRU order != expiration order, so scan.\n",
    "            expired = [k for k, (exp, _) in cache.items() if exp <= now]\n",
    "            for k in expired:\n",
    "                cache.pop(k, None)\n",
    "\n",
    "        @functools.wraps(fn)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            nonlocal hits, misses\n",
    "            k = make_key(args, kwargs)\n",
    "            now = time_func()\n",
    "            _purge_expired(now)\n",
    "\n",
    "            if k in cache:\n",
    "                hits += 1\n",
    "                exp, val = cache.pop(k)\n",
    "                cache[k] = (exp, val)\n",
    "                return val\n",
    "\n",
    "            misses += 1\n",
    "            val = fn(*args, **kwargs)\n",
    "            exp = now + ttl_seconds\n",
    "            cache[k] = (exp, val)\n",
    "            cache.move_to_end(k, last=True)\n",
    "            while len(cache) > maxsize:\n",
    "                cache.popitem(last=False)\n",
    "            return val\n",
    "\n",
    "        def cache_clear():\n",
    "            nonlocal hits, misses\n",
    "            cache.clear()\n",
    "            hits = 0\n",
    "            misses = 0\n",
    "\n",
    "        def cache_info():\n",
    "            return {\n",
    "                'hits': hits,\n",
    "                'misses': misses,\n",
    "                'size': len(cache),\n",
    "                'maxsize': maxsize,\n",
    "                'ttl_seconds': ttl_seconds,\n",
    "            }\n",
    "\n",
    "        wrapper.cache_clear = cache_clear  # type: ignore[attr-defined]\n",
    "        wrapper.cache_info = cache_info    # type: ignore[attr-defined]\n",
    "        return wrapper\n",
    "\n",
    "    return decorate\n"
   ],
   "id": "57bb396c586faf7d",
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "## Exercise 6 — Exception caching policy\n",
    "\n",
    "Implement `memoize_policy(cache_exceptions=False)`:\n",
    "\n",
    "- If `cache_exceptions=False` (recommended default):\n",
    "  - exceptions are **not** cached\n",
    "  - if a call fails, later calls retry the computation\n",
    "- If `cache_exceptions=True`:\n",
    "  - cache exceptions and re-raise the cached exception for future calls\n",
    "\n",
    "Best practice:\n",
    "- Most application logic should not cache transient failures.\n"
   ],
   "id": "7ec81a28ee5663d9"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "solution"
    ],
    "ExecuteTime": {
     "end_time": "2026-02-06T18:23:32.362947800Z",
     "start_time": "2026-02-06T18:23:32.336575400Z"
    }
   },
   "source": [
    "# --- Solution (Exercise 6) ---\n",
    "\n",
    "@dataclass\n",
    "class _CachedException:\n",
    "    exc: BaseException\n",
    "\n",
    "def memoize_policy(\n",
    "    *,\n",
    "    cache_exceptions: bool = False,\n",
    "    key: Callable[[tuple[Any, ...], dict[str, Any]], Hashable] | None = None,\n",
    "):\n",
    "    make_key = key if key is not None else _default_key\n",
    "\n",
    "    def decorate(fn: Callable[..., Any]):\n",
    "        cache: dict[Hashable, Any] = {}\n",
    "\n",
    "        @functools.wraps(fn)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            k = make_key(args, kwargs)\n",
    "            if k in cache:\n",
    "                v = cache[k]\n",
    "                if isinstance(v, _CachedException):\n",
    "                    raise v.exc\n",
    "                return v\n",
    "\n",
    "            try:\n",
    "                v = fn(*args, **kwargs)\n",
    "            except Exception as e:\n",
    "                if cache_exceptions:\n",
    "                    cache[k] = _CachedException(e)\n",
    "                raise\n",
    "\n",
    "            cache[k] = v\n",
    "            return v\n",
    "\n",
    "        def cache_clear():\n",
    "            cache.clear()\n",
    "\n",
    "        wrapper.cache_clear = cache_clear  # type: ignore[attr-defined]\n",
    "        return wrapper\n",
    "\n",
    "    return decorate\n"
   ],
   "id": "fc4884711a7f1230",
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "## Exercise 7 — Async memoization with concurrency de-duplication\n",
    "\n",
    "Implement `async_memoize()` for `async def` functions:\n",
    "\n",
    "Goals:\n",
    "- If multiple tasks call the function concurrently with the same args/kwargs, only compute once.\n",
    "- Cache the **awaited result**, not the coroutine.\n",
    "- If the computation raises, remove the cache entry so future calls can retry.\n",
    "- Expose `cache_clear()` and `cache_info()`.\n",
    "\n",
    "Hint:\n",
    "- Cache `asyncio.Task` objects keyed by args/kwargs.\n"
   ],
   "id": "1e8b74a4566d5e4"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "solution"
    ],
    "ExecuteTime": {
     "end_time": "2026-02-06T18:23:32.887504900Z",
     "start_time": "2026-02-06T18:23:32.846210Z"
    }
   },
   "source": [
    "# --- Solution (Exercise 7) ---\n",
    "\n",
    "def async_memoize(*, key: Callable[[tuple[Any, ...], dict[str, Any]], Hashable] | None = None):\n",
    "    make_key = key if key is not None else _default_key\n",
    "\n",
    "    def decorate(fn: Callable[..., Any]):\n",
    "        if not asyncio.iscoroutinefunction(fn):\n",
    "            raise TypeError('async_memoize can only decorate async functions')\n",
    "\n",
    "        cache: dict[Hashable, asyncio.Task] = {}\n",
    "        hits = 0\n",
    "        misses = 0\n",
    "        lock = asyncio.Lock()\n",
    "\n",
    "        @functools.wraps(fn)\n",
    "        async def wrapper(*args, **kwargs):\n",
    "            nonlocal hits, misses\n",
    "            k = make_key(args, kwargs)\n",
    "\n",
    "            async with lock:\n",
    "                if k in cache:\n",
    "                    hits += 1\n",
    "                    task = cache[k]\n",
    "                else:\n",
    "                    misses += 1\n",
    "                    task = asyncio.create_task(fn(*args, **kwargs))\n",
    "                    cache[k] = task\n",
    "\n",
    "            try:\n",
    "                return await task\n",
    "            except Exception:\n",
    "                # Do not cache failures by default; allow retries.\n",
    "                async with lock:\n",
    "                    if cache.get(k) is task:\n",
    "                        cache.pop(k, None)\n",
    "                raise\n",
    "\n",
    "        def cache_clear():\n",
    "            nonlocal hits, misses\n",
    "            cache.clear()\n",
    "            hits = 0\n",
    "            misses = 0\n",
    "\n",
    "        def cache_info():\n",
    "            return {'hits': hits, 'misses': misses, 'size': len(cache)}\n",
    "\n",
    "        wrapper.cache_clear = cache_clear  # type: ignore[attr-defined]\n",
    "        wrapper.cache_info = cache_info    # type: ignore[attr-defined]\n",
    "        return wrapper\n",
    "\n",
    "    return decorate\n"
   ],
   "id": "6cfd46015b792e7b",
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "## Exercise 8 — Per-instance method memoization (avoid memory leaks)\n",
    "\n",
    "Memoizing methods can accidentally keep instances alive if the cache strongly references `self`.\n",
    "\n",
    "Implement `memoize_method` that:\n",
    "- memoizes results per instance (each instance has its own cache)\n",
    "- uses `WeakKeyDictionary` to avoid keeping instances alive\n",
    "- supports args/kwargs keys\n",
    "- preserves metadata\n",
    "\n",
    "Hint:\n",
    "- Use a descriptor with `__get__` to bind a wrapper per instance.\n"
   ],
   "id": "e8bb4870b51bab44"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "solution"
    ],
    "ExecuteTime": {
     "end_time": "2026-02-06T18:23:33.455545700Z",
     "start_time": "2026-02-06T18:23:33.405891600Z"
    }
   },
   "source": [
    "# --- Solution (Exercise 8) ---\n",
    "# Supports unhashable instances (e.g., normal @dataclass) without memory leaks.\n",
    "\n",
    "import weakref\n",
    "\n",
    "class _BoundMemoizedMethod:\n",
    "    def __init__(self, descriptor: \"memoize_method\", obj: Any):\n",
    "        self._descriptor = descriptor\n",
    "        self._obj = obj\n",
    "        functools.update_wrapper(self, descriptor._fn)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self._descriptor._call(self._obj, *args, **kwargs)\n",
    "\n",
    "    def cache_clear(self):\n",
    "        self._descriptor._clear(self._obj)\n",
    "\n",
    "\n",
    "class memoize_method:\n",
    "    \"\"\"Memoize an instance method per-instance without keeping instances alive.\n",
    "\n",
    "    Note: WeakKeyDictionary requires hashable instances; many dataclasses are unhashable.\n",
    "    This implementation keys by id(obj) and uses weakref.finalize to clean up.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        fn: Callable[..., Any],\n",
    "        *,\n",
    "        key: Callable[[tuple[Any, ...], dict[str, Any]], Hashable] | None = None,\n",
    "    ):\n",
    "        self._fn = fn\n",
    "        self._key = key if key is not None else _default_key\n",
    "\n",
    "        # id(obj) -> per-instance cache\n",
    "        self._caches_by_id: dict[int, dict[Hashable, Any]] = {}\n",
    "\n",
    "        # id(obj) -> finalizer that deletes the cache when obj is GC'd\n",
    "        self._finalizers_by_id: dict[int, weakref.finalize] = {}\n",
    "\n",
    "        functools.update_wrapper(self, fn)\n",
    "\n",
    "    def _drop(self, oid: int) -> None:\n",
    "        self._caches_by_id.pop(oid, None)\n",
    "        self._finalizers_by_id.pop(oid, None)\n",
    "\n",
    "    def _get_cache(self, obj: Any) -> dict[Hashable, Any]:\n",
    "        oid = id(obj)\n",
    "        cache = self._caches_by_id.get(oid)\n",
    "        if cache is None:\n",
    "            cache = {}\n",
    "            self._caches_by_id[oid] = cache\n",
    "            # Ensure cleanup when the instance is garbage-collected\n",
    "            self._finalizers_by_id[oid] = weakref.finalize(obj, self._drop, oid)\n",
    "        return cache\n",
    "\n",
    "    def _call(self, obj: Any, *args, **kwargs):\n",
    "        cache = self._get_cache(obj)\n",
    "        k = self._key(args, kwargs)\n",
    "        if k in cache:\n",
    "            return cache[k]\n",
    "        v = self._fn(obj, *args, **kwargs)\n",
    "        cache[k] = v\n",
    "        return v\n",
    "\n",
    "    def _clear(self, obj: Any) -> None:\n",
    "        cache = self._caches_by_id.get(id(obj))\n",
    "        if cache is not None:\n",
    "            cache.clear()\n",
    "\n",
    "    def __get__(self, obj: Any, objtype=None):\n",
    "        if obj is None:\n",
    "            return self\n",
    "        return _BoundMemoizedMethod(self, obj)\n"
   ],
   "id": "e5c05753b930d1ea",
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "## Exercise 9 — Best practice: use the standard library when possible\n",
    "\n",
    "Tasks:\n",
    "1) Use `functools.lru_cache` to memoize Fibonacci.\n",
    "2) Inspect `.cache_info()` and `.cache_clear()`.\n",
    "3) Show that `inspect.signature` still works due to `__wrapped__`.\n",
    "4) Compare `functools.cache` (unbounded) vs `lru_cache(maxsize=...)`.\n",
    "5) Use `functools.cached_property` for per-instance memoization of an expensive property.\n"
   ],
   "id": "6bcfd6be9b4fb791"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "solution"
    ],
    "ExecuteTime": {
     "end_time": "2026-02-06T18:23:34.160316600Z",
     "start_time": "2026-02-06T18:23:34.066048400Z"
    }
   },
   "source": [
    "# --- Solution (Exercise 9) ---\n",
    "\n",
    "from functools import cache, cached_property, lru_cache\n",
    "\n",
    "@lru_cache(maxsize=256)\n",
    "def fib_lru(n: int) -> int:\n",
    "    if n <= 0:\n",
    "        raise ValueError('n must be >= 1')\n",
    "    return 1 if n <= 2 else fib_lru(n - 1) + fib_lru(n - 2)\n",
    "\n",
    "@cache\n",
    "def fib_cache(n: int) -> int:\n",
    "    if n <= 0:\n",
    "        raise ValueError('n must be >= 1')\n",
    "    return 1 if n <= 2 else fib_cache(n - 1) + fib_cache(n - 2)\n",
    "\n",
    "@dataclass\n",
    "class Expensive:\n",
    "    x: int\n",
    "    calls: int = 0\n",
    "\n",
    "    @cached_property\n",
    "    def heavy(self) -> int:\n",
    "        # Simulate an expensive computation\n",
    "        object.__setattr__(self, 'calls', self.calls + 1)\n",
    "        return self.x * self.x\n"
   ],
   "id": "6a656dff70a12ed0",
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tests"
    ]
   },
   "source": [
    "# Verification / Tests\n",
    "\n",
    "Run this cell to validate correctness and best-practice behavior.\n"
   ],
   "id": "8061ce8b3b63f8ed"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "tests"
    ],
    "ExecuteTime": {
     "end_time": "2026-02-06T18:23:35.073273700Z",
     "start_time": "2026-02-06T18:23:34.968748700Z"
    }
   },
   "source": [
    "# Exercise 1\n",
    "fib_naive_counted.call_count = 0  # type: ignore[attr-defined]\n",
    "assert fib_naive_counted(10) == 55\n",
    "assert fib_naive_counted.call_count > 50  # type: ignore[attr-defined]\n",
    "\n",
    "# Exercise 2: args/kwargs order stability + signature preservation\n",
    "calls = {\"n\": 0}\n",
    "\n",
    "@memoize\n",
    "def add(a: int, b: int = 0, *, c: int = 0) -> int:\n",
    "    calls[\"n\"] += 1\n",
    "    return a + b + c\n",
    "\n",
    "add.cache_clear()  # type: ignore[attr-defined]\n",
    "assert add(1, 2, c=3) == 6\n",
    "assert add(1, 2, c=3) == 6\n",
    "assert add(1, 2, **{\"c\": 3}) == 6\n",
    "info = add.cache_info()  # type: ignore[attr-defined]\n",
    "assert calls[\"n\"] == 1\n",
    "assert info[\"hits\"] == 2 and info[\"misses\"] == 1\n",
    "\n",
    "# Robust signature check (works even with: from __future__ import annotations)\n",
    "assert inspect.signature(add) == inspect.signature(add.__wrapped__)  # type: ignore[attr-defined]\n",
    "\n",
    "# Exercise 3: unhashable inputs handled via freezing\n",
    "calls2 = {\"n\": 0}\n",
    "\n",
    "@memoize_frozen\n",
    "def sum_payload(payload: dict[str, Any]) -> int:\n",
    "    calls2[\"n\"] += 1\n",
    "    return sum(payload[\"values\"]) + payload[\"bias\"]\n",
    "\n",
    "p1 = {\"values\": [1, 2, 3], \"bias\": 10}\n",
    "p2 = {\"bias\": 10, \"values\": [1, 2, 3]}  # same meaning, different order\n",
    "assert sum_payload(p1) == 16\n",
    "assert sum_payload(p2) == 16\n",
    "assert calls2[\"n\"] == 1\n",
    "\n",
    "# Exercise 4: LRU eviction\n",
    "calls3 = {\"n\": 0}\n",
    "\n",
    "@lru_memoize(maxsize=2)\n",
    "def square(x: int) -> int:\n",
    "    calls3[\"n\"] += 1\n",
    "    return x * x\n",
    "\n",
    "square.cache_clear()  # type: ignore[attr-defined]\n",
    "assert square(1) == 1\n",
    "assert square(2) == 4\n",
    "assert square(1) == 1  # hit\n",
    "assert square(3) == 9  # evicts 2 (LRU)\n",
    "assert square.cache_info()[\"size\"] == 2  # type: ignore[attr-defined]\n",
    "before = calls3[\"n\"]\n",
    "square(2)  # recompute (was evicted)\n",
    "assert calls3[\"n\"] == before + 1\n",
    "\n",
    "# Exercise 5: TTL without real sleeping (injectable clock)\n",
    "class FakeClock:\n",
    "    def __init__(self):\n",
    "        self.t = 0.0\n",
    "\n",
    "    def now(self):\n",
    "        return self.t\n",
    "\n",
    "    def advance(self, dt: float):\n",
    "        self.t += dt\n",
    "\n",
    "clk = FakeClock()\n",
    "calls4 = {\"n\": 0}\n",
    "\n",
    "@ttl_memoize(ttl_seconds=5.0, maxsize=10, time_func=clk.now)\n",
    "def inc(x: int) -> int:\n",
    "    calls4[\"n\"] += 1\n",
    "    return x + 1\n",
    "\n",
    "inc.cache_clear()  # type: ignore[attr-defined]\n",
    "assert inc(1) == 2\n",
    "assert inc(1) == 2\n",
    "assert calls4[\"n\"] == 1\n",
    "clk.advance(6.0)\n",
    "assert inc(1) == 2\n",
    "assert calls4[\"n\"] == 2\n",
    "\n",
    "# Exercise 6: exception caching policy\n",
    "state = {\"fail\": True, \"calls\": 0}\n",
    "\n",
    "@memoize_policy(cache_exceptions=False)\n",
    "def flaky(x: int) -> int:\n",
    "    state[\"calls\"] += 1\n",
    "    if state[\"fail\"]:\n",
    "        raise RuntimeError(\"transient\")\n",
    "    return x * 2\n",
    "\n",
    "try:\n",
    "    flaky(2)\n",
    "    raise AssertionError(\"Expected RuntimeError\")\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "state[\"fail\"] = False\n",
    "assert flaky(2) == 4\n",
    "assert state[\"calls\"] == 2\n",
    "\n",
    "state2 = {\"calls\": 0}\n",
    "\n",
    "@memoize_policy(cache_exceptions=True)\n",
    "def always_fails(x: int) -> int:\n",
    "    state2[\"calls\"] += 1\n",
    "    raise ValueError(\"no\")\n",
    "\n",
    "for _ in range(3):\n",
    "    try:\n",
    "        always_fails(1)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "assert state2[\"calls\"] == 1  # cached exception\n",
    "\n",
    "# Exercise 7: async memoize de-duplicates concurrent calls\n",
    "async_calls = {\"n\": 0}\n",
    "\n",
    "@async_memoize()\n",
    "async def slow_double(x: int) -> int:\n",
    "    async_calls[\"n\"] += 1\n",
    "    await asyncio.sleep(0)\n",
    "    return x * 2\n",
    "\n",
    "async def _async_test():\n",
    "    slow_double.cache_clear()  # type: ignore[attr-defined]\n",
    "    res = await asyncio.gather(slow_double(5), slow_double(5), slow_double(5))\n",
    "    assert res == [10, 10, 10]\n",
    "    assert async_calls[\"n\"] == 1\n",
    "    info = slow_double.cache_info()  # type: ignore[attr-defined]\n",
    "    assert info[\"hits\"] == 2 and info[\"misses\"] == 1\n",
    "\n",
    "await _async_test()\n",
    "\n",
    "# Exercise 8: per-instance memoization\n",
    "@dataclass\n",
    "class C:\n",
    "    base: int\n",
    "    calls: int = 0\n",
    "\n",
    "    @memoize_method\n",
    "    def compute(self, x: int) -> int:\n",
    "        self.calls += 1\n",
    "        return self.base + x\n",
    "\n",
    "c1 = C(10)\n",
    "c2 = C(100)\n",
    "assert c1.compute(5) == 15\n",
    "assert c1.compute(5) == 15\n",
    "assert c1.calls == 1\n",
    "assert c2.compute(5) == 105\n",
    "assert c2.calls == 1\n",
    "\n",
    "c1.compute.cache_clear()  # type: ignore[attr-defined]\n",
    "assert c1.compute(5) == 15\n",
    "assert c1.calls == 2\n",
    "\n",
    "# Exercise 9: functools tools\n",
    "fib_lru.cache_clear()\n",
    "assert fib_lru(35) == 9227465\n",
    "ci = fib_lru.cache_info()\n",
    "assert ci.hits >= 0 and ci.misses >= 0\n",
    "\n",
    "# Robust signature check (works even with: from __future__ import annotations)\n",
    "assert inspect.signature(fib_lru) == inspect.signature(fib_lru.__wrapped__)  # type: ignore[attr-defined]\n",
    "\n",
    "fib_cache.cache_clear()\n",
    "assert fib_cache(35) == 9227465\n",
    "\n",
    "e = Expensive(7)\n",
    "assert e.calls == 0\n",
    "assert e.heavy == 49\n",
    "assert e.heavy == 49\n",
    "assert e.calls == 1  # cached_property computed once\n",
    "\n",
    "print(\"All checks passed ✅\")\n"
   ],
   "id": "924df040d2b70f36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All checks passed ✅\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f2d4e8dd45b762c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
